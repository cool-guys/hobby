{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import *\n",
    "\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from imageloader import data_process\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "import copy\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=patience_lr, verbose=1, epsilon=1e-4, mode='min')\n",
    "lr_reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_acc',factor=0.5, patience=20)\n",
    "#model save\n",
    "MODEL_SAVE_FOLDER_PATH = '../model/lstm'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "  os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + '.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_acc',\n",
    "                                verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "#early_stopping = EarlyStopping()\n",
    "\n",
    "# Minmax \n",
    "scaler = MinMaxScaler()\n",
    "scaler_ = MinMaxScaler()\n",
    "\n",
    "# cudnn 오류 해결용(RTX에서만 생기는 문제로 보임))\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 14.845260381698608 seconds ---\n",
      "0\n",
      "7047\n",
      "--- 2.873248338699341 seconds ---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "number = False\n",
    "\n",
    "if(number):\n",
    "    dp = data_process('./DATA/aug/all/train/number',number)\n",
    "    dp.point_data_load()\n",
    "    #dp.image_read()\n",
    "    dp.sequence_50()\n",
    "    dp.image_make()\n",
    "    dp.data_shuffle()\n",
    "  \n",
    "    class_num = 10\n",
    "  \n",
    "else:\n",
    "    dp_train = data_process('./DATA/aug/all/train/Alphabet',number)\n",
    "    dp_train.point_data_load()\n",
    "    #dp.image_read()\n",
    "    dp_train.sequence_50()\n",
    "    dp_train.image_make()\n",
    "    dp_train.data_shuffle()\n",
    "    train_len = np.size(dp_train.point,0)\n",
    "    print(train_len)\n",
    "  \n",
    "    \n",
    "    dp_test = data_process('./DATA/aug/all/test/Alphabet',number)\n",
    "    dp_test.point_data_load()\n",
    "    #dp.image_read()\n",
    "    dp_test.sequence_50()\n",
    "    dp_test.image_make()\n",
    "    dp_test.data_shuffle()\n",
    "    test_len = np.size(dp_test.point,0)\n",
    "  \n",
    "    class_num = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kist-student/anaconda3/envs/tensor/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/kist-student/anaconda3/envs/tensor/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# minmax 실행\n",
    "train_x = dp_train.point[:,:,0].reshape((-1,1))\n",
    "test_x = dp_test.point[:,:,0].reshape((-1,1))\n",
    "\n",
    "train_y = dp_train.point[:,:,1].reshape((-1,1))\n",
    "test_y = dp_test.point[:,:,1].reshape((-1,1))\n",
    "\n",
    "data_x = scaler.fit_transform(train_x).reshape((-1,64,1))\n",
    "data_test_x = scaler.transform(test_x).reshape((-1,64,1))\n",
    "\n",
    "data_y = scaler_.fit_transform(train_y).reshape((-1,64,1))\n",
    "data_test_y = scaler_.transform(test_y).reshape((-1,64,1))\n",
    "\n",
    "data = np.hstack((data_x,data_y)).reshape((-1,64,2),order='F')\n",
    "data_test = np.hstack((data_test_x,data_test_y)).reshape((-1,64,2),order='F')\n",
    "\n",
    "#train set test set 나누기\n",
    "X_train = data[:,:,:]\n",
    "#X_train_ = copy.deepcopy(dp.point)\n",
    "X_test = data_test[:,:,:]\n",
    "X_test_ = copy.deepcopy(data[:,:,:])\n",
    "\n",
    "X_train_img = dp_train.images[:]\n",
    "X_test_img = dp_test.images[:]\n",
    "Y_train = dp_train.label[:]\n",
    "Y_test = dp_test.label[:]\n",
    "\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train,num_classes=class_num, dtype='float32')\n",
    "Y_test = keras.utils.to_categorical(Y_test,num_classes=class_num, dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudnn 오류 해결용(RTX에서만 생기는 문제로 보임))\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kist-student/anaconda3/envs/tensor/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/kist-student/anaconda3/envs/tensor/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input_2 = Input(shape=(64, 2))\n",
    "\n",
    "x_2 = Conv1D(32,kernel_size=4, padding='same',strides=1)(input_2)\n",
    "x_2 = BatchNormalization(momentum=0.8)(x_2)\n",
    "x_2 = LeakyReLU(0.2)(x_2)\n",
    "x_2 = Dropout(0.5)(x_2)\n",
    "\n",
    "x_2 = Conv1D(64,kernel_size=5, strides=1, padding='same')(x_2)\n",
    "x_2 = BatchNormalization(momentum=0.8)(x_2)\n",
    "x_2 = LeakyReLU(alpha=0.2)(x_2)\n",
    "x_2 = Dropout(0.5)(x_2)\n",
    "\n",
    "x_2 = Conv1D(128, kernel_size=6, strides=1, padding='same')(x_2)\n",
    "x_2 = BatchNormalization(momentum=0.8)(x_2)\n",
    "x_2 = LeakyReLU(0.2)(x_2)\n",
    "x_2 = Dropout(0.5)(x_2)\n",
    "\n",
    "\n",
    "x_2 = Conv1D(256, kernel_size=7, strides=1, padding='same')(x_2)\n",
    "x_2 = BatchNormalization(momentum=0.8)(x_2)\n",
    "x_2 = LeakyReLU(0.2)(x_2)\n",
    "x_2 = Dropout(0.5)(x_2)\n",
    "\n",
    "x_2 = Conv1D(512, kernel_size=8, strides=1, padding='same')(x_2)\n",
    "x_2 = BatchNormalization(momentum=0.8)(x_2)\n",
    "x_2 = LeakyReLU(0.2)(x_2)\n",
    "x_2 = Dropout(0.5)(x_2)\n",
    "\n",
    "x_2 = GlobalAveragePooling1D()(x_2)\n",
    "\n",
    "x_2 = Dense(class_num,activation='softmax')(x_2)\n",
    "\n",
    "model = Model(inputs=input_2, outputs = x_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 2)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 64, 32)            288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 32)            128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 64, 64)            10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64)            256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 64, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 128)           512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 64, 256)           229632    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 256)           1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 64, 512)           1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64, 512)           2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64, 512)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26)                13338     \n",
      "=================================================================\n",
      "Total params: 1,355,898\n",
      "Trainable params: 1,353,914\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kist-student/anaconda3/envs/tensor/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7047 samples, validate on 1393 samples\n",
      "Epoch 1/250\n",
      "7047/7047 [==============================] - 5s 686us/step - loss: 2.0246 - acc: 0.3988 - val_loss: 2.1381 - val_acc: 0.2850\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.28500, saving model to ../model/lstm.hdf5\n",
      "Epoch 2/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 1.2181 - acc: 0.6406 - val_loss: 1.3696 - val_acc: 0.5879\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.28500 to 0.58794, saving model to ../model/lstm.hdf5\n",
      "Epoch 3/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.8306 - acc: 0.7731 - val_loss: 0.9040 - val_acc: 0.7617\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.58794 to 0.76167, saving model to ../model/lstm.hdf5\n",
      "Epoch 4/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.5512 - acc: 0.8555 - val_loss: 0.7974 - val_acc: 0.7681\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.76167 to 0.76813, saving model to ../model/lstm.hdf5\n",
      "Epoch 5/250\n",
      "7047/7047 [==============================] - 1s 177us/step - loss: 0.4494 - acc: 0.8828 - val_loss: 0.5028 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.76813 to 0.85714, saving model to ../model/lstm.hdf5\n",
      "Epoch 6/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.3235 - acc: 0.9168 - val_loss: 0.4308 - val_acc: 0.8844\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.85714 to 0.88442, saving model to ../model/lstm.hdf5\n",
      "Epoch 7/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.2588 - acc: 0.9354 - val_loss: 0.4299 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.88442\n",
      "Epoch 8/250\n",
      "7047/7047 [==============================] - 1s 180us/step - loss: 0.2348 - acc: 0.9373 - val_loss: 0.3877 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.88442 to 0.90093, saving model to ../model/lstm.hdf5\n",
      "Epoch 9/250\n",
      "7047/7047 [==============================] - 1s 166us/step - loss: 0.2136 - acc: 0.9404 - val_loss: 0.2915 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.90093 to 0.92462, saving model to ../model/lstm.hdf5\n",
      "Epoch 10/250\n",
      "7047/7047 [==============================] - 1s 167us/step - loss: 0.1820 - acc: 0.9513 - val_loss: 0.3241 - val_acc: 0.9103\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92462\n",
      "Epoch 11/250\n",
      "7047/7047 [==============================] - 1s 186us/step - loss: 0.1545 - acc: 0.9588 - val_loss: 0.2736 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92462\n",
      "Epoch 12/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.1624 - acc: 0.9550 - val_loss: 0.2581 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92462\n",
      "Epoch 13/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.1384 - acc: 0.9617 - val_loss: 0.2342 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.92462 to 0.93539, saving model to ../model/lstm.hdf5\n",
      "Epoch 14/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.1524 - acc: 0.9584 - val_loss: 0.2297 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93539\n",
      "Epoch 15/250\n",
      "7047/7047 [==============================] - 1s 177us/step - loss: 0.1186 - acc: 0.9659 - val_loss: 0.2854 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93539\n",
      "Epoch 16/250\n",
      "7047/7047 [==============================] - 1s 166us/step - loss: 0.1035 - acc: 0.9701 - val_loss: 0.2603 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93539\n",
      "Epoch 17/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0989 - acc: 0.9720 - val_loss: 0.2933 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93539\n",
      "Epoch 18/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0955 - acc: 0.9730 - val_loss: 0.2111 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93539\n",
      "Epoch 19/250\n",
      "7047/7047 [==============================] - 1s 167us/step - loss: 0.1237 - acc: 0.9601 - val_loss: 0.2728 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93539\n",
      "Epoch 20/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.1070 - acc: 0.9669 - val_loss: 0.2392 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.93539\n",
      "Epoch 21/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0825 - acc: 0.9772 - val_loss: 0.2153 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.93539 to 0.94042, saving model to ../model/lstm.hdf5\n",
      "Epoch 22/250\n",
      "7047/7047 [==============================] - 1s 166us/step - loss: 0.1077 - acc: 0.9668 - val_loss: 0.2246 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.94042\n",
      "Epoch 23/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0862 - acc: 0.9742 - val_loss: 0.2596 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.94042\n",
      "Epoch 24/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0773 - acc: 0.9789 - val_loss: 0.2255 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.94042\n",
      "Epoch 25/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0812 - acc: 0.9733 - val_loss: 0.2577 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.94042\n",
      "Epoch 26/250\n",
      "7047/7047 [==============================] - 1s 178us/step - loss: 0.1015 - acc: 0.9695 - val_loss: 0.2223 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.94042\n",
      "Epoch 27/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0706 - acc: 0.9820 - val_loss: 0.2262 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.94042\n",
      "Epoch 28/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0703 - acc: 0.9787 - val_loss: 0.2406 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.94042\n",
      "Epoch 29/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0644 - acc: 0.9803 - val_loss: 0.2540 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.94042\n",
      "Epoch 30/250\n",
      "7047/7047 [==============================] - 1s 180us/step - loss: 0.0966 - acc: 0.9711 - val_loss: 0.1764 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.94042 to 0.94616, saving model to ../model/lstm.hdf5\n",
      "Epoch 31/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0599 - acc: 0.9835 - val_loss: 0.2132 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.94616\n",
      "Epoch 32/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0579 - acc: 0.9827 - val_loss: 0.2509 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.94616\n",
      "Epoch 33/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0559 - acc: 0.9820 - val_loss: 0.1656 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.94616 to 0.94975, saving model to ../model/lstm.hdf5\n",
      "Epoch 34/250\n",
      "7047/7047 [==============================] - 1s 166us/step - loss: 0.0634 - acc: 0.9803 - val_loss: 0.2860 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.94975\n",
      "Epoch 35/250\n",
      "7047/7047 [==============================] - 1s 177us/step - loss: 0.0580 - acc: 0.9813 - val_loss: 0.2100 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.94975\n",
      "Epoch 36/250\n",
      "7047/7047 [==============================] - 1s 175us/step - loss: 0.0506 - acc: 0.9831 - val_loss: 0.2072 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.94975\n",
      "Epoch 37/250\n",
      "7047/7047 [==============================] - 1s 181us/step - loss: 0.0609 - acc: 0.9814 - val_loss: 0.2676 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.94975\n",
      "Epoch 38/250\n",
      "7047/7047 [==============================] - 1s 192us/step - loss: 0.0627 - acc: 0.9806 - val_loss: 0.2184 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.94975\n",
      "Epoch 39/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0571 - acc: 0.9813 - val_loss: 0.2744 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.94975\n",
      "Epoch 40/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0720 - acc: 0.9774 - val_loss: 0.2306 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.94975\n",
      "Epoch 41/250\n",
      "7047/7047 [==============================] - 1s 166us/step - loss: 0.0506 - acc: 0.9847 - val_loss: 0.2308 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.94975\n",
      "Epoch 42/250\n",
      "7047/7047 [==============================] - 1s 176us/step - loss: 0.0469 - acc: 0.9851 - val_loss: 0.2319 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.94975\n",
      "Epoch 43/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0405 - acc: 0.9889 - val_loss: 0.2165 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.94975\n",
      "Epoch 44/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0438 - acc: 0.9868 - val_loss: 0.2534 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.94975\n",
      "Epoch 45/250\n",
      "7047/7047 [==============================] - 1s 179us/step - loss: 0.0811 - acc: 0.9760 - val_loss: 0.3069 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.94975\n",
      "Epoch 46/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0447 - acc: 0.9854 - val_loss: 0.2441 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.94975\n",
      "Epoch 47/250\n",
      "7047/7047 [==============================] - 1s 176us/step - loss: 0.0555 - acc: 0.9827 - val_loss: 0.2605 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.94975\n",
      "Epoch 48/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0486 - acc: 0.9840 - val_loss: 0.1834 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.94975\n",
      "Epoch 49/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0437 - acc: 0.9852 - val_loss: 0.1963 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.94975\n",
      "Epoch 50/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0377 - acc: 0.9881 - val_loss: 0.2104 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.94975\n",
      "Epoch 51/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0401 - acc: 0.9882 - val_loss: 0.2314 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.94975\n",
      "Epoch 52/250\n",
      "7047/7047 [==============================] - 1s 177us/step - loss: 0.0969 - acc: 0.9728 - val_loss: 0.2383 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.94975\n",
      "Epoch 53/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0797 - acc: 0.9766 - val_loss: 0.2061 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.94975\n",
      "Epoch 54/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0505 - acc: 0.9850 - val_loss: 0.1579 - val_acc: 0.9548\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.94975 to 0.95477, saving model to ../model/lstm.hdf5\n",
      "Epoch 55/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0375 - acc: 0.9889 - val_loss: 0.2409 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.95477\n",
      "Epoch 56/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0368 - acc: 0.9894 - val_loss: 0.1797 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.95477\n",
      "Epoch 57/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0382 - acc: 0.9868 - val_loss: 0.2065 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.95477\n",
      "Epoch 58/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0333 - acc: 0.9895 - val_loss: 0.1945 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.95477\n",
      "Epoch 59/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0338 - acc: 0.9902 - val_loss: 0.2027 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.95477\n",
      "Epoch 60/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0387 - acc: 0.9885 - val_loss: 0.2263 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.95477\n",
      "Epoch 61/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0344 - acc: 0.9896 - val_loss: 0.1723 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.95477\n",
      "Epoch 62/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0292 - acc: 0.9906 - val_loss: 0.2039 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.95477\n",
      "Epoch 63/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0293 - acc: 0.9912 - val_loss: 0.1890 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.95477\n",
      "Epoch 64/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0283 - acc: 0.9906 - val_loss: 0.2363 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.95477\n",
      "Epoch 65/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0305 - acc: 0.9896 - val_loss: 0.2674 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.95477\n",
      "Epoch 66/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0307 - acc: 0.9902 - val_loss: 0.2115 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.95477\n",
      "Epoch 67/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0285 - acc: 0.9918 - val_loss: 0.2792 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.95477\n",
      "Epoch 68/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0295 - acc: 0.9922 - val_loss: 0.2497 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.95477\n",
      "Epoch 69/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0402 - acc: 0.9868 - val_loss: 0.1829 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.95477\n",
      "Epoch 70/250\n",
      "7047/7047 [==============================] - 1s 179us/step - loss: 0.0313 - acc: 0.9895 - val_loss: 0.1886 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.95477\n",
      "Epoch 71/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0301 - acc: 0.9911 - val_loss: 0.2280 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.95477\n",
      "Epoch 72/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0573 - acc: 0.9828 - val_loss: 0.2241 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.95477\n",
      "Epoch 73/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0359 - acc: 0.9882 - val_loss: 0.2041 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.95477\n",
      "Epoch 74/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0282 - acc: 0.9913 - val_loss: 0.2258 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.95477\n",
      "Epoch 75/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0303 - acc: 0.9909 - val_loss: 0.2045 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.95477\n",
      "Epoch 76/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0269 - acc: 0.9923 - val_loss: 0.2320 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.95477\n",
      "Epoch 77/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0279 - acc: 0.9918 - val_loss: 0.1811 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.95477\n",
      "Epoch 78/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0294 - acc: 0.9915 - val_loss: 0.2272 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.95477\n",
      "Epoch 79/250\n",
      "7047/7047 [==============================] - 1s 179us/step - loss: 0.0299 - acc: 0.9899 - val_loss: 0.1876 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.95477\n",
      "Epoch 80/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0301 - acc: 0.9906 - val_loss: 0.1883 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.95477\n",
      "Epoch 81/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0271 - acc: 0.9922 - val_loss: 0.1850 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.95477\n",
      "Epoch 82/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0244 - acc: 0.9928 - val_loss: 0.2048 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.95477\n",
      "Epoch 83/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7047/7047 [==============================] - 1s 177us/step - loss: 0.0243 - acc: 0.9926 - val_loss: 0.2073 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.95477\n",
      "Epoch 84/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0262 - acc: 0.9916 - val_loss: 0.2104 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.95477\n",
      "Epoch 85/250\n",
      "7047/7047 [==============================] - 1s 178us/step - loss: 0.0308 - acc: 0.9899 - val_loss: 0.2479 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.95477\n",
      "Epoch 86/250\n",
      "7047/7047 [==============================] - 1s 179us/step - loss: 0.0269 - acc: 0.9916 - val_loss: 0.2256 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.95477\n",
      "Epoch 87/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0357 - acc: 0.9877 - val_loss: 0.2807 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.95477\n",
      "Epoch 88/250\n",
      "7047/7047 [==============================] - 1s 189us/step - loss: 0.0241 - acc: 0.9933 - val_loss: 0.2183 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.95477\n",
      "Epoch 89/250\n",
      "7047/7047 [==============================] - 1s 183us/step - loss: 0.0273 - acc: 0.9911 - val_loss: 0.2335 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.95477\n",
      "Epoch 90/250\n",
      "7047/7047 [==============================] - 1s 180us/step - loss: 0.0240 - acc: 0.9925 - val_loss: 0.2397 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.95477\n",
      "Epoch 91/250\n",
      "7047/7047 [==============================] - 1s 181us/step - loss: 0.0225 - acc: 0.9935 - val_loss: 0.2067 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.95477\n",
      "Epoch 92/250\n",
      "7047/7047 [==============================] - 1s 181us/step - loss: 0.0219 - acc: 0.9942 - val_loss: 0.2069 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.95477\n",
      "Epoch 93/250\n",
      "7047/7047 [==============================] - 1s 180us/step - loss: 0.0271 - acc: 0.9915 - val_loss: 0.2104 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.95477\n",
      "Epoch 94/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0246 - acc: 0.9935 - val_loss: 0.1886 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.95477\n",
      "Epoch 95/250\n",
      "7047/7047 [==============================] - 1s 178us/step - loss: 0.0229 - acc: 0.9936 - val_loss: 0.1982 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.95477\n",
      "Epoch 96/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0210 - acc: 0.9939 - val_loss: 0.2009 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.95477\n",
      "Epoch 97/250\n",
      "7047/7047 [==============================] - 1s 180us/step - loss: 0.0283 - acc: 0.9911 - val_loss: 0.1988 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.95477\n",
      "Epoch 98/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0269 - acc: 0.9913 - val_loss: 0.2674 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.95477\n",
      "Epoch 99/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0234 - acc: 0.9936 - val_loss: 0.2575 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.95477\n",
      "Epoch 100/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0230 - acc: 0.9936 - val_loss: 0.2311 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.95477\n",
      "Epoch 101/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0240 - acc: 0.9925 - val_loss: 0.2301 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.95477\n",
      "Epoch 102/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0265 - acc: 0.9918 - val_loss: 0.2658 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.95477\n",
      "Epoch 103/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0250 - acc: 0.9923 - val_loss: 0.2446 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.95477\n",
      "Epoch 104/250\n",
      "7047/7047 [==============================] - 1s 180us/step - loss: 0.0298 - acc: 0.9909 - val_loss: 0.2867 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.95477\n",
      "Epoch 105/250\n",
      "7047/7047 [==============================] - 1s 176us/step - loss: 0.0297 - acc: 0.9902 - val_loss: 0.2329 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.95477\n",
      "Epoch 106/250\n",
      "7047/7047 [==============================] - 1s 179us/step - loss: 0.0242 - acc: 0.9938 - val_loss: 0.2625 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.95477\n",
      "Epoch 107/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0227 - acc: 0.9915 - val_loss: 0.2782 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.95477\n",
      "Epoch 108/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0223 - acc: 0.9932 - val_loss: 0.2594 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.95477\n",
      "Epoch 109/250\n",
      "7047/7047 [==============================] - 1s 183us/step - loss: 0.0212 - acc: 0.9939 - val_loss: 0.2290 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.95477\n",
      "Epoch 110/250\n",
      "7047/7047 [==============================] - 1s 181us/step - loss: 0.0215 - acc: 0.9936 - val_loss: 0.2220 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.95477\n",
      "Epoch 111/250\n",
      "7047/7047 [==============================] - 1s 178us/step - loss: 0.0190 - acc: 0.9955 - val_loss: 0.1832 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.95477\n",
      "Epoch 112/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0212 - acc: 0.9925 - val_loss: 0.1875 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.95477\n",
      "Epoch 113/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0215 - acc: 0.9925 - val_loss: 0.2668 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.95477\n",
      "Epoch 114/250\n",
      "7047/7047 [==============================] - 1s 176us/step - loss: 0.0242 - acc: 0.9932 - val_loss: 0.2158 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.95477\n",
      "Epoch 115/250\n",
      "7047/7047 [==============================] - 1s 180us/step - loss: 0.0217 - acc: 0.9919 - val_loss: 0.2004 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.95477\n",
      "Epoch 116/250\n",
      "7047/7047 [==============================] - 1s 181us/step - loss: 0.0229 - acc: 0.9938 - val_loss: 0.2474 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.95477\n",
      "Epoch 117/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0246 - acc: 0.9919 - val_loss: 0.2180 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.95477\n",
      "Epoch 118/250\n",
      "7047/7047 [==============================] - 1s 181us/step - loss: 0.0197 - acc: 0.9939 - val_loss: 0.2127 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.95477\n",
      "Epoch 119/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0196 - acc: 0.9940 - val_loss: 0.1803 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.95477\n",
      "Epoch 120/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0203 - acc: 0.9943 - val_loss: 0.2188 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.95477\n",
      "Epoch 121/250\n",
      "7047/7047 [==============================] - 1s 176us/step - loss: 0.0214 - acc: 0.9942 - val_loss: 0.2332 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.95477\n",
      "Epoch 122/250\n",
      "7047/7047 [==============================] - 1s 184us/step - loss: 0.0179 - acc: 0.9950 - val_loss: 0.1970 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.95477\n",
      "Epoch 123/250\n",
      "7047/7047 [==============================] - 1s 179us/step - loss: 0.0227 - acc: 0.9933 - val_loss: 0.1998 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.95477\n",
      "Epoch 124/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0247 - acc: 0.9922 - val_loss: 0.3285 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.95477\n",
      "Epoch 125/250\n",
      "7047/7047 [==============================] - 1s 176us/step - loss: 0.0219 - acc: 0.9936 - val_loss: 0.2900 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.95477\n",
      "Epoch 126/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0251 - acc: 0.9919 - val_loss: 0.2658 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.95477\n",
      "Epoch 127/250\n",
      "7047/7047 [==============================] - 1s 182us/step - loss: 0.0204 - acc: 0.9943 - val_loss: 0.3121 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.95477\n",
      "Epoch 128/250\n",
      "7047/7047 [==============================] - 1s 187us/step - loss: 0.0217 - acc: 0.9935 - val_loss: 0.2509 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.95477\n",
      "Epoch 129/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0194 - acc: 0.9947 - val_loss: 0.2437 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.95477\n",
      "Epoch 130/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0202 - acc: 0.9940 - val_loss: 0.2330 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.95477\n",
      "Epoch 131/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0212 - acc: 0.9940 - val_loss: 0.2176 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.95477\n",
      "Epoch 132/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0215 - acc: 0.9935 - val_loss: 0.2418 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.95477\n",
      "Epoch 133/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0214 - acc: 0.9936 - val_loss: 0.1829 - val_acc: 0.9512\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.95477\n",
      "Epoch 134/250\n",
      "7047/7047 [==============================] - 1s 177us/step - loss: 0.0223 - acc: 0.9943 - val_loss: 0.1867 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.95477\n",
      "Epoch 135/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0208 - acc: 0.9932 - val_loss: 0.1866 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.95477\n",
      "Epoch 136/250\n",
      "7047/7047 [==============================] - 1s 175us/step - loss: 0.0202 - acc: 0.9939 - val_loss: 0.2282 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.95477\n",
      "Epoch 137/250\n",
      "7047/7047 [==============================] - 1s 177us/step - loss: 0.0211 - acc: 0.9928 - val_loss: 0.1840 - val_acc: 0.9526\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.95477\n",
      "Epoch 138/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0202 - acc: 0.9936 - val_loss: 0.2299 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.95477\n",
      "Epoch 139/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0213 - acc: 0.9939 - val_loss: 0.2352 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.95477\n",
      "Epoch 140/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.2233 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.95477\n",
      "Epoch 141/250\n",
      "7047/7047 [==============================] - 1s 176us/step - loss: 0.0191 - acc: 0.9945 - val_loss: 0.2020 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.95477\n",
      "Epoch 142/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0212 - acc: 0.9925 - val_loss: 0.2625 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.95477\n",
      "Epoch 143/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.2033 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.95477\n",
      "Epoch 144/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0219 - acc: 0.9928 - val_loss: 0.2215 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.95477\n",
      "Epoch 145/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0195 - acc: 0.9936 - val_loss: 0.2202 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.95477\n",
      "Epoch 146/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0214 - acc: 0.9932 - val_loss: 0.2184 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.95477\n",
      "Epoch 147/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0224 - acc: 0.9930 - val_loss: 0.1939 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.95477\n",
      "Epoch 148/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0191 - acc: 0.9933 - val_loss: 0.2315 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.95477\n",
      "Epoch 149/250\n",
      "7047/7047 [==============================] - 1s 179us/step - loss: 0.0189 - acc: 0.9947 - val_loss: 0.2448 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.95477\n",
      "Epoch 150/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0210 - acc: 0.9928 - val_loss: 0.2478 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.95477\n",
      "Epoch 151/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0187 - acc: 0.9943 - val_loss: 0.1879 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.95477\n",
      "Epoch 152/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0211 - acc: 0.9930 - val_loss: 0.1534 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.95477 to 0.95836, saving model to ../model/lstm.hdf5\n",
      "Epoch 153/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0193 - acc: 0.9947 - val_loss: 0.2813 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.95836\n",
      "Epoch 154/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0199 - acc: 0.9942 - val_loss: 0.2507 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.95836\n",
      "Epoch 155/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0222 - acc: 0.9938 - val_loss: 0.2610 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.95836\n",
      "Epoch 156/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0217 - acc: 0.9940 - val_loss: 0.2397 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.95836\n",
      "Epoch 157/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0194 - acc: 0.9938 - val_loss: 0.2198 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.95836\n",
      "Epoch 158/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0201 - acc: 0.9932 - val_loss: 0.2281 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.95836\n",
      "Epoch 159/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0196 - acc: 0.9935 - val_loss: 0.2158 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.95836\n",
      "Epoch 160/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0194 - acc: 0.9940 - val_loss: 0.1974 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.95836\n",
      "Epoch 161/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0224 - acc: 0.9926 - val_loss: 0.2685 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.95836\n",
      "Epoch 162/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0205 - acc: 0.9940 - val_loss: 0.1715 - val_acc: 0.9569\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.95836\n",
      "Epoch 163/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0217 - acc: 0.9939 - val_loss: 0.2231 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.95836\n",
      "Epoch 164/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0191 - acc: 0.9945 - val_loss: 0.2031 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.95836\n",
      "Epoch 165/250\n",
      "7047/7047 [==============================] - 1s 179us/step - loss: 0.0178 - acc: 0.9955 - val_loss: 0.2225 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.95836\n",
      "Epoch 166/250\n",
      "7047/7047 [==============================] - 1s 181us/step - loss: 0.0219 - acc: 0.9932 - val_loss: 0.2254 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.95836\n",
      "Epoch 167/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0201 - acc: 0.9939 - val_loss: 0.2514 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.95836\n",
      "Epoch 168/250\n",
      "7047/7047 [==============================] - 1s 179us/step - loss: 0.0228 - acc: 0.9922 - val_loss: 0.2260 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.95836\n",
      "Epoch 169/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7047/7047 [==============================] - 1s 181us/step - loss: 0.0193 - acc: 0.9939 - val_loss: 0.1983 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.95836\n",
      "Epoch 170/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0190 - acc: 0.9942 - val_loss: 0.2196 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.95836\n",
      "Epoch 171/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0228 - acc: 0.9930 - val_loss: 0.2535 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.95836\n",
      "Epoch 172/250\n",
      "7047/7047 [==============================] - 1s 175us/step - loss: 0.0213 - acc: 0.9939 - val_loss: 0.2001 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.95836\n",
      "Epoch 173/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0194 - acc: 0.9942 - val_loss: 0.2428 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.95836\n",
      "Epoch 174/250\n",
      "7047/7047 [==============================] - 1s 177us/step - loss: 0.0188 - acc: 0.9940 - val_loss: 0.2225 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.95836\n",
      "Epoch 175/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0203 - acc: 0.9930 - val_loss: 0.2402 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.95836\n",
      "Epoch 176/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0204 - acc: 0.9935 - val_loss: 0.2388 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.95836\n",
      "Epoch 177/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0189 - acc: 0.9940 - val_loss: 0.2190 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.95836\n",
      "Epoch 178/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0185 - acc: 0.9950 - val_loss: 0.2225 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.95836\n",
      "Epoch 179/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0175 - acc: 0.9943 - val_loss: 0.2243 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.95836\n",
      "Epoch 180/250\n",
      "7047/7047 [==============================] - 1s 176us/step - loss: 0.0206 - acc: 0.9939 - val_loss: 0.1937 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.95836\n",
      "Epoch 181/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0185 - acc: 0.9939 - val_loss: 0.1963 - val_acc: 0.9512\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.95836\n",
      "Epoch 182/250\n",
      "7047/7047 [==============================] - 1s 180us/step - loss: 0.0184 - acc: 0.9956 - val_loss: 0.2121 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.95836\n",
      "Epoch 183/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0201 - acc: 0.9946 - val_loss: 0.2316 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.95836\n",
      "Epoch 184/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0165 - acc: 0.9953 - val_loss: 0.2370 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.95836\n",
      "Epoch 185/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0209 - acc: 0.9935 - val_loss: 0.1964 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.95836\n",
      "Epoch 186/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0175 - acc: 0.9947 - val_loss: 0.2392 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.95836\n",
      "Epoch 187/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0200 - acc: 0.9945 - val_loss: 0.2049 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.95836\n",
      "Epoch 188/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0177 - acc: 0.9957 - val_loss: 0.1825 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.95836\n",
      "Epoch 189/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0191 - acc: 0.9946 - val_loss: 0.2069 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.95836\n",
      "Epoch 190/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0187 - acc: 0.9950 - val_loss: 0.2490 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.95836\n",
      "Epoch 191/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0226 - acc: 0.9925 - val_loss: 0.2345 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.95836\n",
      "Epoch 192/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0213 - acc: 0.9930 - val_loss: 0.2525 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.95836\n",
      "Epoch 193/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0190 - acc: 0.9933 - val_loss: 0.2014 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.95836\n",
      "Epoch 194/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0194 - acc: 0.9945 - val_loss: 0.2044 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.95836\n",
      "Epoch 195/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0160 - acc: 0.9953 - val_loss: 0.2502 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.95836\n",
      "Epoch 196/250\n",
      "7047/7047 [==============================] - 1s 177us/step - loss: 0.0196 - acc: 0.9943 - val_loss: 0.2134 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.95836\n",
      "Epoch 197/250\n",
      "7047/7047 [==============================] - 1s 180us/step - loss: 0.0183 - acc: 0.9956 - val_loss: 0.2280 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.95836\n",
      "Epoch 198/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0193 - acc: 0.9942 - val_loss: 0.2362 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.95836\n",
      "Epoch 199/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0179 - acc: 0.9942 - val_loss: 0.2347 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.95836\n",
      "Epoch 200/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0191 - acc: 0.9940 - val_loss: 0.2151 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.95836\n",
      "Epoch 201/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0190 - acc: 0.9935 - val_loss: 0.2212 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.95836\n",
      "Epoch 202/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0172 - acc: 0.9947 - val_loss: 0.1948 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.95836\n",
      "Epoch 203/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0170 - acc: 0.9947 - val_loss: 0.2228 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.95836\n",
      "Epoch 204/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0215 - acc: 0.9932 - val_loss: 0.2531 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.95836\n",
      "Epoch 205/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0210 - acc: 0.9936 - val_loss: 0.2669 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.95836\n",
      "Epoch 206/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0214 - acc: 0.9939 - val_loss: 0.2194 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.95836\n",
      "Epoch 207/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0194 - acc: 0.9942 - val_loss: 0.1802 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.95836\n",
      "Epoch 208/250\n",
      "7047/7047 [==============================] - 1s 177us/step - loss: 0.0213 - acc: 0.9922 - val_loss: 0.2296 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.95836\n",
      "Epoch 209/250\n",
      "7047/7047 [==============================] - 1s 167us/step - loss: 0.0210 - acc: 0.9945 - val_loss: 0.2289 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.95836\n",
      "Epoch 210/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0170 - acc: 0.9952 - val_loss: 0.2133 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.95836\n",
      "Epoch 211/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0201 - acc: 0.9945 - val_loss: 0.1883 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.95836\n",
      "Epoch 212/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7047/7047 [==============================] - 1s 175us/step - loss: 0.0192 - acc: 0.9943 - val_loss: 0.2636 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.95836\n",
      "Epoch 213/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0179 - acc: 0.9953 - val_loss: 0.2200 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.95836\n",
      "Epoch 214/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0197 - acc: 0.9945 - val_loss: 0.2132 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.95836\n",
      "Epoch 215/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0178 - acc: 0.9945 - val_loss: 0.2173 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.95836\n",
      "Epoch 216/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0208 - acc: 0.9929 - val_loss: 0.1944 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.95836\n",
      "Epoch 217/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0201 - acc: 0.9938 - val_loss: 0.1696 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.95836\n",
      "Epoch 218/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0174 - acc: 0.9952 - val_loss: 0.1988 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.95836\n",
      "Epoch 219/250\n",
      "7047/7047 [==============================] - 1s 187us/step - loss: 0.0204 - acc: 0.9933 - val_loss: 0.2150 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.95836\n",
      "Epoch 220/250\n",
      "7047/7047 [==============================] - 1s 175us/step - loss: 0.0190 - acc: 0.9945 - val_loss: 0.2614 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.95836\n",
      "Epoch 221/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0173 - acc: 0.9947 - val_loss: 0.2501 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.95836\n",
      "Epoch 222/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0191 - acc: 0.9940 - val_loss: 0.2196 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.95836\n",
      "Epoch 223/250\n",
      "7047/7047 [==============================] - 1s 179us/step - loss: 0.0193 - acc: 0.9946 - val_loss: 0.1957 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.95836\n",
      "Epoch 224/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0164 - acc: 0.9952 - val_loss: 0.2176 - val_acc: 0.9404\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.95836\n",
      "Epoch 225/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0168 - acc: 0.9960 - val_loss: 0.2924 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.95836\n",
      "Epoch 226/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0180 - acc: 0.9943 - val_loss: 0.2130 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.95836\n",
      "Epoch 227/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0185 - acc: 0.9953 - val_loss: 0.1915 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.95836\n",
      "Epoch 228/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0177 - acc: 0.9946 - val_loss: 0.1920 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.95836\n",
      "Epoch 229/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0176 - acc: 0.9947 - val_loss: 0.2220 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.95836\n",
      "Epoch 230/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0190 - acc: 0.9942 - val_loss: 0.2063 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.95836\n",
      "Epoch 231/250\n",
      "7047/7047 [==============================] - 1s 177us/step - loss: 0.0187 - acc: 0.9943 - val_loss: 0.2542 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.95836\n",
      "Epoch 232/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0170 - acc: 0.9957 - val_loss: 0.2597 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.95836\n",
      "Epoch 233/250\n",
      "7047/7047 [==============================] - 1s 191us/step - loss: 0.0181 - acc: 0.9947 - val_loss: 0.2575 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.95836\n",
      "Epoch 234/250\n",
      "7047/7047 [==============================] - 1s 178us/step - loss: 0.0199 - acc: 0.9930 - val_loss: 0.2338 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.95836\n",
      "Epoch 235/250\n",
      "7047/7047 [==============================] - 1s 167us/step - loss: 0.0185 - acc: 0.9940 - val_loss: 0.2692 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.95836\n",
      "Epoch 236/250\n",
      "7047/7047 [==============================] - 1s 172us/step - loss: 0.0183 - acc: 0.9935 - val_loss: 0.2354 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.95836\n",
      "Epoch 237/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0163 - acc: 0.9952 - val_loss: 0.2045 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.95836\n",
      "Epoch 238/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0193 - acc: 0.9933 - val_loss: 0.1956 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.95836\n",
      "Epoch 239/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0209 - acc: 0.9936 - val_loss: 0.2155 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.95836\n",
      "Epoch 240/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0199 - acc: 0.9945 - val_loss: 0.1677 - val_acc: 0.9526\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.95836\n",
      "Epoch 241/250\n",
      "7047/7047 [==============================] - 1s 171us/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.2130 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.95836\n",
      "Epoch 242/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0197 - acc: 0.9945 - val_loss: 0.1992 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.95836\n",
      "Epoch 243/250\n",
      "7047/7047 [==============================] - 1s 176us/step - loss: 0.0169 - acc: 0.9957 - val_loss: 0.2786 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.95836\n",
      "Epoch 244/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0170 - acc: 0.9956 - val_loss: 0.2518 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.95836\n",
      "Epoch 245/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0178 - acc: 0.9946 - val_loss: 0.2327 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.95836\n",
      "Epoch 246/250\n",
      "7047/7047 [==============================] - 1s 170us/step - loss: 0.0189 - acc: 0.9943 - val_loss: 0.2053 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.95836\n",
      "Epoch 247/250\n",
      "7047/7047 [==============================] - 1s 169us/step - loss: 0.0204 - acc: 0.9938 - val_loss: 0.2551 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.95836\n",
      "Epoch 248/250\n",
      "7047/7047 [==============================] - 1s 173us/step - loss: 0.0174 - acc: 0.9952 - val_loss: 0.1747 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.95836\n",
      "Epoch 249/250\n",
      "7047/7047 [==============================] - 1s 174us/step - loss: 0.0203 - acc: 0.9936 - val_loss: 0.2412 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.95836\n",
      "Epoch 250/250\n",
      "7047/7047 [==============================] - 1s 168us/step - loss: 0.0185 - acc: 0.9938 - val_loss: 0.1807 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.95836\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=keras.optimizers.Adam(lr=0.001,epsilon=1e-04),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_train,Y_train,epochs=250,batch_size=128,validation_data=(X_test,Y_test),callbacks=[cb_checkpoint,lr_reduce])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_weights = [layer.get_weights() for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_FOLDER_PATH = './model/cnn_test'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "  os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + '.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_acc',\n",
    "                                verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dp_train.images[:]\n",
    "X_test = dp_test.images[:]\n",
    "Y_train = dp_train.label[:]\n",
    "Y_test = dp_test.label[:]\n",
    "\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train,num_classes=class_num, dtype='float32')\n",
    "Y_test = keras.utils.to_categorical(Y_test,num_classes=class_num, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(28, 28, 1))\n",
    "\n",
    "#x_1 = conv1_layer_2(input_1)\n",
    "#x_1 = conv2_layer_2(x_1)\n",
    "\n",
    "x_1 = Conv2D(32, kernel_size=3, padding=\"valid\", activation = 'relu')(input_1)\n",
    "x_1 = BatchNormalization()(x_1)\n",
    "x_1 = ReLU()(x_1)\n",
    "x_1 = Dropout(0.45)(x_1)\n",
    "\n",
    "x_1 = Conv2D(64, kernel_size=3, padding=\"valid\", activation = 'relu')(x_1)\n",
    "x_1 = BatchNormalization()(x_1)\n",
    "x_1 = ReLU()(x_1)\n",
    "x_1 = Dropout(0.45)(x_1)\n",
    "\n",
    "x_1 = Conv2D(128, kernel_size=3, padding=\"valid\", activation = 'relu')(x_1)\n",
    "x_1 = BatchNormalization()(x_1)\n",
    "x_1 = ReLU()(x_1)\n",
    "x_1 = Dropout(0.45)(x_1)\n",
    "\n",
    "x_1 = Conv2D(256, kernel_size=3, padding=\"valid\", activation = 'relu')(x_1)\n",
    "x_1 = BatchNormalization()(x_1)\n",
    "x_1 = ReLU()(x_1)\n",
    "x_1 = Dropout(0.45)(x_1)\n",
    "\n",
    "x_1 = GlobalAveragePooling2D()(x_1)\n",
    "x_1 = Dropout(0.45)(x_1)\n",
    "\n",
    "x_1 = Dense(class_num,activation='softmax')(x_1)\n",
    "\n",
    "model_2 = Model(inputs=input_1, outputs=x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 22, 22, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 22, 22, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 20, 20, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_16 (ReLU)              (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 26)                6682      \n",
      "=================================================================\n",
      "Total params: 396,442\n",
      "Trainable params: 395,482\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7047 samples, validate on 1393 samples\n",
      "Epoch 1/250\n",
      "7047/7047 [==============================] - 3s 478us/step - loss: 2.9047 - acc: 0.1646 - val_loss: 2.8796 - val_acc: 0.1271\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.12706, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 2/250\n",
      "7047/7047 [==============================] - 2s 300us/step - loss: 2.1002 - acc: 0.4271 - val_loss: 2.2926 - val_acc: 0.2649\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.12706 to 0.26490, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 3/250\n",
      "7047/7047 [==============================] - 2s 302us/step - loss: 1.5005 - acc: 0.6230 - val_loss: 1.6337 - val_acc: 0.5671\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.26490 to 0.56712, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 4/250\n",
      "7047/7047 [==============================] - 2s 301us/step - loss: 1.0867 - acc: 0.7539 - val_loss: 1.4662 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.56712 to 0.61091, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 5/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.8264 - acc: 0.8196 - val_loss: 1.1118 - val_acc: 0.6791\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.61091 to 0.67911, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 6/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.6388 - acc: 0.8655 - val_loss: 0.8889 - val_acc: 0.7674\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.67911 to 0.76741, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 7/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.5163 - acc: 0.8974 - val_loss: 0.9213 - val_acc: 0.7050\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.76741\n",
      "Epoch 8/250\n",
      "7047/7047 [==============================] - 2s 302us/step - loss: 0.4314 - acc: 0.9117 - val_loss: 0.7633 - val_acc: 0.7631\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.76741\n",
      "Epoch 9/250\n",
      "7047/7047 [==============================] - 2s 302us/step - loss: 0.3667 - acc: 0.9255 - val_loss: 0.7060 - val_acc: 0.8191\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.76741 to 0.81910, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 10/250\n",
      "7047/7047 [==============================] - 2s 303us/step - loss: 0.3044 - acc: 0.9424 - val_loss: 0.6725 - val_acc: 0.7933\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.81910\n",
      "Epoch 11/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.2654 - acc: 0.9430 - val_loss: 0.7912 - val_acc: 0.7990\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.81910\n",
      "Epoch 12/250\n",
      "7047/7047 [==============================] - 2s 299us/step - loss: 0.2353 - acc: 0.9523 - val_loss: 0.6360 - val_acc: 0.7954\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.81910\n",
      "Epoch 13/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.2162 - acc: 0.9523 - val_loss: 0.4465 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.81910 to 0.88155, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 14/250\n",
      "7047/7047 [==============================] - 2s 302us/step - loss: 0.1969 - acc: 0.9600 - val_loss: 0.5054 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.88155\n",
      "Epoch 15/250\n",
      "7047/7047 [==============================] - 2s 299us/step - loss: 0.1883 - acc: 0.9584 - val_loss: 0.5842 - val_acc: 0.8105\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.88155\n",
      "Epoch 16/250\n",
      "7047/7047 [==============================] - 2s 301us/step - loss: 0.1681 - acc: 0.9630 - val_loss: 0.4208 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.88155\n",
      "Epoch 17/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.1690 - acc: 0.9635 - val_loss: 0.4007 - val_acc: 0.8923\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.88155 to 0.89232, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 18/250\n",
      "7047/7047 [==============================] - 2s 296us/step - loss: 0.1765 - acc: 0.9600 - val_loss: 0.4265 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.89232\n",
      "Epoch 19/250\n",
      "7047/7047 [==============================] - 2s 300us/step - loss: 0.1413 - acc: 0.9682 - val_loss: 0.3994 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.89232\n",
      "Epoch 20/250\n",
      "7047/7047 [==============================] - 2s 302us/step - loss: 0.1233 - acc: 0.9730 - val_loss: 0.4459 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.89232\n",
      "Epoch 21/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.1233 - acc: 0.9699 - val_loss: 0.6848 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.89232\n",
      "Epoch 22/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.1116 - acc: 0.9763 - val_loss: 0.3645 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.89232 to 0.90668, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 23/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.1081 - acc: 0.9763 - val_loss: 0.3692 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.90668 to 0.90811, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 24/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0993 - acc: 0.9764 - val_loss: 0.4086 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.90811\n",
      "Epoch 25/250\n",
      "7047/7047 [==============================] - 2s 299us/step - loss: 0.0940 - acc: 0.9786 - val_loss: 0.4139 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.90811\n",
      "Epoch 26/250\n",
      "7047/7047 [==============================] - 2s 311us/step - loss: 0.0918 - acc: 0.9793 - val_loss: 0.4596 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.90811\n",
      "Epoch 27/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0949 - acc: 0.9769 - val_loss: 0.3258 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.90811 to 0.91385, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 28/250\n",
      "7047/7047 [==============================] - 2s 296us/step - loss: 0.0819 - acc: 0.9825 - val_loss: 0.4058 - val_acc: 0.8916\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.91385\n",
      "Epoch 29/250\n",
      "7047/7047 [==============================] - 2s 299us/step - loss: 0.0941 - acc: 0.9773 - val_loss: 0.7491 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.91385\n",
      "Epoch 30/250\n",
      "7047/7047 [==============================] - 2s 305us/step - loss: 0.0842 - acc: 0.9800 - val_loss: 0.4896 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.91385\n",
      "Epoch 31/250\n",
      "7047/7047 [==============================] - 2s 308us/step - loss: 0.0806 - acc: 0.9818 - val_loss: 0.3955 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.91385\n",
      "Epoch 32/250\n",
      "7047/7047 [==============================] - 2s 301us/step - loss: 0.0818 - acc: 0.9807 - val_loss: 0.4279 - val_acc: 0.9038\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.91385\n",
      "Epoch 33/250\n",
      "7047/7047 [==============================] - 2s 306us/step - loss: 0.0779 - acc: 0.9807 - val_loss: 0.4953 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.91385\n",
      "Epoch 34/250\n",
      "7047/7047 [==============================] - 2s 301us/step - loss: 0.0683 - acc: 0.9847 - val_loss: 0.6982 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.91385\n",
      "Epoch 35/250\n",
      "7047/7047 [==============================] - 2s 302us/step - loss: 0.0846 - acc: 0.9790 - val_loss: 0.4342 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.91385\n",
      "Epoch 36/250\n",
      "7047/7047 [==============================] - 2s 306us/step - loss: 0.0660 - acc: 0.9842 - val_loss: 0.3807 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.91385\n",
      "Epoch 37/250\n",
      "7047/7047 [==============================] - 2s 310us/step - loss: 0.0649 - acc: 0.9840 - val_loss: 0.3617 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.91385\n",
      "Epoch 38/250\n",
      "7047/7047 [==============================] - 2s 303us/step - loss: 0.0712 - acc: 0.9817 - val_loss: 0.3520 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.91385\n",
      "Epoch 39/250\n",
      "7047/7047 [==============================] - 2s 303us/step - loss: 0.0676 - acc: 0.9828 - val_loss: 0.3957 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.91385 to 0.91385, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 40/250\n",
      "7047/7047 [==============================] - 2s 301us/step - loss: 0.0633 - acc: 0.9852 - val_loss: 0.4147 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.91385\n",
      "Epoch 41/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7047/7047 [==============================] - 2s 305us/step - loss: 0.0604 - acc: 0.9861 - val_loss: 0.3760 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.91385\n",
      "Epoch 42/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0520 - acc: 0.9881 - val_loss: 0.3830 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.91385 to 0.91457, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 43/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0579 - acc: 0.9854 - val_loss: 0.4278 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.91457\n",
      "Epoch 44/250\n",
      "7047/7047 [==============================] - 2s 305us/step - loss: 0.0563 - acc: 0.9860 - val_loss: 0.3929 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.91457\n",
      "Epoch 45/250\n",
      "7047/7047 [==============================] - 2s 304us/step - loss: 0.0517 - acc: 0.9884 - val_loss: 0.4260 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.91457\n",
      "Epoch 46/250\n",
      "7047/7047 [==============================] - 2s 300us/step - loss: 0.0497 - acc: 0.9879 - val_loss: 0.3935 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.91457\n",
      "Epoch 47/250\n",
      "7047/7047 [==============================] - 2s 299us/step - loss: 0.0469 - acc: 0.9891 - val_loss: 0.4766 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.91457\n",
      "Epoch 48/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0651 - acc: 0.9828 - val_loss: 0.3999 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.91457\n",
      "Epoch 49/250\n",
      "7047/7047 [==============================] - 2s 302us/step - loss: 0.0531 - acc: 0.9858 - val_loss: 0.3656 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.91457 to 0.91888, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 50/250\n",
      "7047/7047 [==============================] - 2s 302us/step - loss: 0.0492 - acc: 0.9884 - val_loss: 0.4071 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.91888\n",
      "Epoch 51/250\n",
      "7047/7047 [==============================] - 2s 300us/step - loss: 0.0541 - acc: 0.9869 - val_loss: 0.3930 - val_acc: 0.9103\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.91888\n",
      "Epoch 52/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0450 - acc: 0.9886 - val_loss: 0.3745 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.91888 to 0.92391, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 53/250\n",
      "7047/7047 [==============================] - 2s 299us/step - loss: 0.0428 - acc: 0.9901 - val_loss: 0.4969 - val_acc: 0.9002\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.92391\n",
      "Epoch 54/250\n",
      "7047/7047 [==============================] - 2s 304us/step - loss: 0.0463 - acc: 0.9884 - val_loss: 0.4401 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.92391\n",
      "Epoch 55/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0422 - acc: 0.9881 - val_loss: 0.8021 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.92391\n",
      "Epoch 56/250\n",
      "7047/7047 [==============================] - 2s 302us/step - loss: 0.0390 - acc: 0.9923 - val_loss: 0.4521 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.92391\n",
      "Epoch 57/250\n",
      "7047/7047 [==============================] - 2s 304us/step - loss: 0.0435 - acc: 0.9901 - val_loss: 0.4314 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.92391\n",
      "Epoch 58/250\n",
      "7047/7047 [==============================] - 2s 302us/step - loss: 0.0439 - acc: 0.9889 - val_loss: 0.3965 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.92391\n",
      "Epoch 59/250\n",
      "7047/7047 [==============================] - 2s 296us/step - loss: 0.0507 - acc: 0.9861 - val_loss: 0.3661 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.92391\n",
      "Epoch 60/250\n",
      "7047/7047 [==============================] - 2s 303us/step - loss: 0.0453 - acc: 0.9879 - val_loss: 0.5591 - val_acc: 0.8866\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.92391\n",
      "Epoch 61/250\n",
      "7047/7047 [==============================] - 2s 300us/step - loss: 0.0404 - acc: 0.9894 - val_loss: 0.3734 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.92391\n",
      "Epoch 62/250\n",
      "7047/7047 [==============================] - 2s 308us/step - loss: 0.0524 - acc: 0.9867 - val_loss: 0.4109 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.92391 to 0.92534, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 63/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0398 - acc: 0.9889 - val_loss: 0.3528 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.92534 to 0.92965, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 64/250\n",
      "7047/7047 [==============================] - 2s 296us/step - loss: 0.0391 - acc: 0.9905 - val_loss: 0.4180 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.92965\n",
      "Epoch 65/250\n",
      "7047/7047 [==============================] - 2s 300us/step - loss: 0.0350 - acc: 0.9912 - val_loss: 0.5686 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.92965\n",
      "Epoch 66/250\n",
      "7047/7047 [==============================] - 2s 300us/step - loss: 0.0360 - acc: 0.9894 - val_loss: 0.4291 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.92965\n",
      "Epoch 67/250\n",
      "7047/7047 [==============================] - 2s 310us/step - loss: 0.0323 - acc: 0.9926 - val_loss: 0.4222 - val_acc: 0.9110\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.92965\n",
      "Epoch 68/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0493 - acc: 0.9885 - val_loss: 0.6683 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.92965\n",
      "Epoch 69/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0384 - acc: 0.9901 - val_loss: 0.4829 - val_acc: 0.9045\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.92965\n",
      "Epoch 70/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0395 - acc: 0.9881 - val_loss: 0.5308 - val_acc: 0.8887\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.92965\n",
      "Epoch 71/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0342 - acc: 0.9925 - val_loss: 0.4041 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.92965\n",
      "Epoch 72/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0309 - acc: 0.9922 - val_loss: 0.4157 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.92965\n",
      "Epoch 73/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0399 - acc: 0.9908 - val_loss: 0.4146 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.92965\n",
      "Epoch 74/250\n",
      "7047/7047 [==============================] - 2s 299us/step - loss: 0.0354 - acc: 0.9908 - val_loss: 0.4787 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.92965\n",
      "Epoch 75/250\n",
      "7047/7047 [==============================] - 2s 302us/step - loss: 0.0320 - acc: 0.9908 - val_loss: 0.4676 - val_acc: 0.9124\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.92965\n",
      "Epoch 76/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0385 - acc: 0.9905 - val_loss: 0.4453 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.92965\n",
      "Epoch 77/250\n",
      "7047/7047 [==============================] - 2s 293us/step - loss: 0.0327 - acc: 0.9919 - val_loss: 0.5218 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.92965\n",
      "Epoch 78/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0389 - acc: 0.9899 - val_loss: 0.4858 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.92965\n",
      "Epoch 79/250\n",
      "7047/7047 [==============================] - 2s 290us/step - loss: 0.0301 - acc: 0.9918 - val_loss: 0.3633 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.92965\n",
      "Epoch 80/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0312 - acc: 0.9932 - val_loss: 0.4993 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.92965\n",
      "Epoch 81/250\n",
      "7047/7047 [==============================] - 2s 299us/step - loss: 0.0295 - acc: 0.9933 - val_loss: 0.4093 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.92965\n",
      "Epoch 82/250\n",
      "7047/7047 [==============================] - 2s 294us/step - loss: 0.0286 - acc: 0.9930 - val_loss: 0.4725 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.92965\n",
      "Epoch 83/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0280 - acc: 0.9930 - val_loss: 0.4608 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.92965\n",
      "Epoch 84/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0247 - acc: 0.9936 - val_loss: 0.4550 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.92965\n",
      "Epoch 85/250\n",
      "7047/7047 [==============================] - 2s 300us/step - loss: 0.0261 - acc: 0.9932 - val_loss: 0.4597 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.92965\n",
      "Epoch 86/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0242 - acc: 0.9940 - val_loss: 0.4787 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.92965\n",
      "Epoch 87/250\n",
      "7047/7047 [==============================] - 2s 291us/step - loss: 0.0225 - acc: 0.9946 - val_loss: 0.4279 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.92965\n",
      "Epoch 88/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0244 - acc: 0.9942 - val_loss: 0.4506 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.92965\n",
      "Epoch 89/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0220 - acc: 0.9947 - val_loss: 0.4253 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.92965\n",
      "Epoch 90/250\n",
      "7047/7047 [==============================] - 2s 294us/step - loss: 0.0220 - acc: 0.9952 - val_loss: 0.4215 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.92965\n",
      "Epoch 91/250\n",
      "7047/7047 [==============================] - 2s 294us/step - loss: 0.0222 - acc: 0.9933 - val_loss: 0.4502 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.92965\n",
      "Epoch 92/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0195 - acc: 0.9956 - val_loss: 0.4566 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.92965\n",
      "Epoch 93/250\n",
      "7047/7047 [==============================] - 2s 294us/step - loss: 0.0202 - acc: 0.9950 - val_loss: 0.4393 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.92965\n",
      "Epoch 94/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0227 - acc: 0.9940 - val_loss: 0.6867 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.92965\n",
      "Epoch 95/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0199 - acc: 0.9959 - val_loss: 0.4770 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.92965\n",
      "Epoch 96/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0209 - acc: 0.9952 - val_loss: 0.4679 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.92965\n",
      "Epoch 97/250\n",
      "7047/7047 [==============================] - 2s 301us/step - loss: 0.0197 - acc: 0.9955 - val_loss: 0.4301 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.92965\n",
      "Epoch 98/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0195 - acc: 0.9956 - val_loss: 0.4631 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.92965\n",
      "Epoch 99/250\n",
      "7047/7047 [==============================] - 2s 299us/step - loss: 0.0215 - acc: 0.9952 - val_loss: 0.4554 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.92965\n",
      "Epoch 100/250\n",
      "7047/7047 [==============================] - 2s 291us/step - loss: 0.0214 - acc: 0.9950 - val_loss: 0.4301 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.92965\n",
      "Epoch 101/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0153 - acc: 0.9973 - val_loss: 0.4268 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.92965\n",
      "Epoch 102/250\n",
      "7047/7047 [==============================] - 2s 305us/step - loss: 0.0198 - acc: 0.9955 - val_loss: 0.4565 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.92965\n",
      "Epoch 103/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0296 - acc: 0.9911 - val_loss: 0.5381 - val_acc: 0.9110\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.92965\n",
      "Epoch 104/250\n",
      "7047/7047 [==============================] - 2s 300us/step - loss: 0.0245 - acc: 0.9933 - val_loss: 0.4706 - val_acc: 0.9174\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.92965\n",
      "Epoch 105/250\n",
      "7047/7047 [==============================] - 2s 303us/step - loss: 0.0230 - acc: 0.9933 - val_loss: 0.4362 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.92965\n",
      "Epoch 106/250\n",
      "7047/7047 [==============================] - 2s 296us/step - loss: 0.0223 - acc: 0.9940 - val_loss: 0.4300 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.92965\n",
      "Epoch 107/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0168 - acc: 0.9965 - val_loss: 0.4480 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.92965\n",
      "Epoch 108/250\n",
      "7047/7047 [==============================] - 2s 299us/step - loss: 0.0190 - acc: 0.9953 - val_loss: 0.4413 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.92965\n",
      "Epoch 109/250\n",
      "7047/7047 [==============================] - 2s 300us/step - loss: 0.0193 - acc: 0.9955 - val_loss: 0.4465 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.92965\n",
      "Epoch 110/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0215 - acc: 0.9946 - val_loss: 0.4565 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.92965\n",
      "Epoch 111/250\n",
      "7047/7047 [==============================] - 2s 296us/step - loss: 0.0176 - acc: 0.9956 - val_loss: 0.4509 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.92965\n",
      "Epoch 112/250\n",
      "7047/7047 [==============================] - 2s 305us/step - loss: 0.0200 - acc: 0.9952 - val_loss: 0.4289 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.92965 to 0.93180, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 113/250\n",
      "7047/7047 [==============================] - 2s 286us/step - loss: 0.0210 - acc: 0.9938 - val_loss: 0.4373 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.93180\n",
      "Epoch 114/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0179 - acc: 0.9955 - val_loss: 0.4287 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.93180\n",
      "Epoch 115/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0179 - acc: 0.9963 - val_loss: 0.4228 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.93180\n",
      "Epoch 116/250\n",
      "7047/7047 [==============================] - 2s 286us/step - loss: 0.0215 - acc: 0.9940 - val_loss: 0.4432 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.93180\n",
      "Epoch 117/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0192 - acc: 0.9947 - val_loss: 0.4613 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.93180\n",
      "Epoch 118/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0191 - acc: 0.9953 - val_loss: 0.4603 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.93180\n",
      "Epoch 119/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0175 - acc: 0.9952 - val_loss: 0.4495 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.93180\n",
      "Epoch 120/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0169 - acc: 0.9963 - val_loss: 0.4340 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.93180\n",
      "Epoch 121/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0170 - acc: 0.9959 - val_loss: 0.4561 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.93180\n",
      "Epoch 122/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0189 - acc: 0.9957 - val_loss: 0.4484 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.93180\n",
      "Epoch 123/250\n",
      "7047/7047 [==============================] - 2s 284us/step - loss: 0.0169 - acc: 0.9957 - val_loss: 0.4652 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.93180\n",
      "Epoch 124/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0148 - acc: 0.9969 - val_loss: 0.4636 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.93180\n",
      "Epoch 125/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0176 - acc: 0.9955 - val_loss: 0.4617 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.93180\n",
      "Epoch 126/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7047/7047 [==============================] - 2s 286us/step - loss: 0.0170 - acc: 0.9959 - val_loss: 0.4564 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.93180\n",
      "Epoch 127/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0166 - acc: 0.9965 - val_loss: 0.4564 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.93180\n",
      "Epoch 128/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0175 - acc: 0.9960 - val_loss: 0.4522 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.93180\n",
      "Epoch 129/250\n",
      "7047/7047 [==============================] - 2s 284us/step - loss: 0.0166 - acc: 0.9959 - val_loss: 0.4726 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.93180\n",
      "Epoch 130/250\n",
      "7047/7047 [==============================] - 2s 284us/step - loss: 0.0157 - acc: 0.9966 - val_loss: 0.4519 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.93180\n",
      "Epoch 131/250\n",
      "7047/7047 [==============================] - 2s 284us/step - loss: 0.0179 - acc: 0.9965 - val_loss: 0.4648 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.93180\n",
      "Epoch 132/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0161 - acc: 0.9967 - val_loss: 0.4750 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.93180\n",
      "Epoch 133/250\n",
      "7047/7047 [==============================] - 2s 285us/step - loss: 0.0158 - acc: 0.9967 - val_loss: 0.4808 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.93180\n",
      "Epoch 134/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0148 - acc: 0.9972 - val_loss: 0.4780 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.93180\n",
      "Epoch 135/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0165 - acc: 0.9956 - val_loss: 0.4610 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.93180\n",
      "Epoch 136/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0145 - acc: 0.9967 - val_loss: 0.4561 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.93180\n",
      "Epoch 137/250\n",
      "7047/7047 [==============================] - 2s 284us/step - loss: 0.0156 - acc: 0.9967 - val_loss: 0.4511 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.93180\n",
      "Epoch 138/250\n",
      "7047/7047 [==============================] - 2s 287us/step - loss: 0.0141 - acc: 0.9970 - val_loss: 0.4511 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.93180\n",
      "Epoch 139/250\n",
      "7047/7047 [==============================] - 2s 285us/step - loss: 0.0153 - acc: 0.9959 - val_loss: 0.4557 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.93180\n",
      "Epoch 140/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0149 - acc: 0.9966 - val_loss: 0.4461 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.93180\n",
      "Epoch 141/250\n",
      "7047/7047 [==============================] - 2s 284us/step - loss: 0.0152 - acc: 0.9967 - val_loss: 0.4278 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.93180\n",
      "Epoch 142/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0178 - acc: 0.9952 - val_loss: 0.4441 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00142: val_acc improved from 0.93180 to 0.93180, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 143/250\n",
      "7047/7047 [==============================] - 2s 284us/step - loss: 0.0161 - acc: 0.9959 - val_loss: 0.4428 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.93180\n",
      "Epoch 144/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0151 - acc: 0.9966 - val_loss: 0.4565 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.93180\n",
      "Epoch 145/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0150 - acc: 0.9967 - val_loss: 0.4428 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.93180\n",
      "Epoch 146/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0139 - acc: 0.9967 - val_loss: 0.4363 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.93180\n",
      "Epoch 147/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0154 - acc: 0.9972 - val_loss: 0.4504 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.93180 to 0.93252, saving model to ./model/cnn_test.hdf5\n",
      "Epoch 148/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0156 - acc: 0.9962 - val_loss: 0.4669 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.93252\n",
      "Epoch 149/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0153 - acc: 0.9967 - val_loss: 0.4719 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.93252\n",
      "Epoch 150/250\n",
      "7047/7047 [==============================] - 2s 284us/step - loss: 0.0167 - acc: 0.9950 - val_loss: 0.4638 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.93252\n",
      "Epoch 151/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0154 - acc: 0.9969 - val_loss: 0.4703 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.93252\n",
      "Epoch 152/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0142 - acc: 0.9960 - val_loss: 0.4675 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.93252\n",
      "Epoch 153/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0137 - acc: 0.9965 - val_loss: 0.4755 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.93252\n",
      "Epoch 154/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0167 - acc: 0.9960 - val_loss: 0.4633 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.93252\n",
      "Epoch 155/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0136 - acc: 0.9967 - val_loss: 0.4557 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.93252\n",
      "Epoch 156/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0123 - acc: 0.9972 - val_loss: 0.4554 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.93252\n",
      "Epoch 157/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0164 - acc: 0.9962 - val_loss: 0.4567 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.93252\n",
      "Epoch 158/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0166 - acc: 0.9963 - val_loss: 0.4483 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.93252\n",
      "Epoch 159/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0158 - acc: 0.9963 - val_loss: 0.4403 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.93252\n",
      "Epoch 160/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0153 - acc: 0.9962 - val_loss: 0.4519 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.93252\n",
      "Epoch 161/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0146 - acc: 0.9965 - val_loss: 0.4634 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.93252\n",
      "Epoch 162/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0140 - acc: 0.9959 - val_loss: 0.4668 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.93252\n",
      "Epoch 163/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0135 - acc: 0.9976 - val_loss: 0.4706 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.93252\n",
      "Epoch 164/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0148 - acc: 0.9969 - val_loss: 0.4714 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.93252\n",
      "Epoch 165/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0149 - acc: 0.9967 - val_loss: 0.4731 - val_acc: 0.9239\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.93252\n",
      "Epoch 166/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0134 - acc: 0.9967 - val_loss: 0.4577 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.93252\n",
      "Epoch 167/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0163 - acc: 0.9963 - val_loss: 0.4585 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.93252\n",
      "Epoch 168/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0160 - acc: 0.9963 - val_loss: 0.4701 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.93252\n",
      "Epoch 169/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0132 - acc: 0.9970 - val_loss: 0.4648 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.93252\n",
      "Epoch 170/250\n",
      "7047/7047 [==============================] - 2s 280us/step - loss: 0.0148 - acc: 0.9969 - val_loss: 0.4612 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.93252\n",
      "Epoch 171/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0147 - acc: 0.9967 - val_loss: 0.4594 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.93252\n",
      "Epoch 172/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0166 - acc: 0.9952 - val_loss: 0.4654 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.93252\n",
      "Epoch 173/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0137 - acc: 0.9963 - val_loss: 0.4608 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.93252\n",
      "Epoch 174/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0154 - acc: 0.9963 - val_loss: 0.4590 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.93252\n",
      "Epoch 175/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0137 - acc: 0.9972 - val_loss: 0.4707 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.93252\n",
      "Epoch 176/250\n",
      "7047/7047 [==============================] - 2s 286us/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.4679 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.93252\n",
      "Epoch 177/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0155 - acc: 0.9969 - val_loss: 0.4689 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.93252\n",
      "Epoch 178/250\n",
      "7047/7047 [==============================] - 2s 281us/step - loss: 0.0153 - acc: 0.9960 - val_loss: 0.4609 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.93252\n",
      "Epoch 179/250\n",
      "7047/7047 [==============================] - 2s 282us/step - loss: 0.0138 - acc: 0.9967 - val_loss: 0.4586 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.93252\n",
      "Epoch 180/250\n",
      "7047/7047 [==============================] - 2s 286us/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.4655 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.93252\n",
      "Epoch 181/250\n",
      "7047/7047 [==============================] - 2s 291us/step - loss: 0.0125 - acc: 0.9973 - val_loss: 0.4643 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.93252\n",
      "Epoch 182/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0150 - acc: 0.9956 - val_loss: 0.4629 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.93252\n",
      "Epoch 183/250\n",
      "7047/7047 [==============================] - 2s 289us/step - loss: 0.0133 - acc: 0.9972 - val_loss: 0.4644 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.93252\n",
      "Epoch 184/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0138 - acc: 0.9966 - val_loss: 0.4595 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.93252\n",
      "Epoch 185/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0112 - acc: 0.9980 - val_loss: 0.4523 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.93252\n",
      "Epoch 186/250\n",
      "7047/7047 [==============================] - 2s 287us/step - loss: 0.0125 - acc: 0.9962 - val_loss: 0.4581 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.93252\n",
      "Epoch 187/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0137 - acc: 0.9970 - val_loss: 0.4605 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.93252\n",
      "Epoch 188/250\n",
      "7047/7047 [==============================] - 2s 283us/step - loss: 0.0135 - acc: 0.9974 - val_loss: 0.4604 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.93252\n",
      "Epoch 189/250\n",
      "7047/7047 [==============================] - 2s 294us/step - loss: 0.0133 - acc: 0.9970 - val_loss: 0.4615 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.93252\n",
      "Epoch 190/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0129 - acc: 0.9973 - val_loss: 0.4607 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.93252\n",
      "Epoch 191/250\n",
      "7047/7047 [==============================] - 2s 290us/step - loss: 0.0141 - acc: 0.9963 - val_loss: 0.4622 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.93252\n",
      "Epoch 192/250\n",
      "7047/7047 [==============================] - 2s 290us/step - loss: 0.0124 - acc: 0.9966 - val_loss: 0.4626 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.93252\n",
      "Epoch 193/250\n",
      "7047/7047 [==============================] - 2s 300us/step - loss: 0.0129 - acc: 0.9976 - val_loss: 0.4616 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.93252\n",
      "Epoch 194/250\n",
      "7047/7047 [==============================] - 2s 299us/step - loss: 0.0131 - acc: 0.9962 - val_loss: 0.4619 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.93252\n",
      "Epoch 195/250\n",
      "7047/7047 [==============================] - 2s 287us/step - loss: 0.0135 - acc: 0.9969 - val_loss: 0.4618 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.93252\n",
      "Epoch 196/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0148 - acc: 0.9957 - val_loss: 0.4582 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.93252\n",
      "Epoch 197/250\n",
      "7047/7047 [==============================] - 2s 290us/step - loss: 0.0159 - acc: 0.9955 - val_loss: 0.4609 - val_acc: 0.9296\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.93252\n",
      "Epoch 198/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0135 - acc: 0.9967 - val_loss: 0.4598 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.93252\n",
      "Epoch 199/250\n",
      "7047/7047 [==============================] - 2s 289us/step - loss: 0.0142 - acc: 0.9967 - val_loss: 0.4583 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.93252\n",
      "Epoch 200/250\n",
      "7047/7047 [==============================] - 2s 285us/step - loss: 0.0125 - acc: 0.9974 - val_loss: 0.4596 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.93252\n",
      "Epoch 201/250\n",
      "7047/7047 [==============================] - 2s 301us/step - loss: 0.0166 - acc: 0.9966 - val_loss: 0.4566 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.93252\n",
      "Epoch 202/250\n",
      "7047/7047 [==============================] - 2s 285us/step - loss: 0.0124 - acc: 0.9973 - val_loss: 0.4586 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.93252\n",
      "Epoch 203/250\n",
      "7047/7047 [==============================] - 2s 287us/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.4618 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.93252\n",
      "Epoch 204/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0132 - acc: 0.9976 - val_loss: 0.4598 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.93252\n",
      "Epoch 205/250\n",
      "7047/7047 [==============================] - 2s 287us/step - loss: 0.0137 - acc: 0.9959 - val_loss: 0.4563 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.93252\n",
      "Epoch 206/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0128 - acc: 0.9966 - val_loss: 0.4571 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.93252\n",
      "Epoch 207/250\n",
      "7047/7047 [==============================] - 2s 291us/step - loss: 0.0116 - acc: 0.9972 - val_loss: 0.4587 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.93252\n",
      "Epoch 208/250\n",
      "7047/7047 [==============================] - 2s 294us/step - loss: 0.0134 - acc: 0.9973 - val_loss: 0.4606 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.93252\n",
      "Epoch 209/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0127 - acc: 0.9970 - val_loss: 0.4608 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.93252\n",
      "Epoch 210/250\n",
      "7047/7047 [==============================] - 2s 309us/step - loss: 0.0120 - acc: 0.9974 - val_loss: 0.4622 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.93252\n",
      "Epoch 211/250\n",
      "7047/7047 [==============================] - 2s 303us/step - loss: 0.0131 - acc: 0.9969 - val_loss: 0.4625 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.93252\n",
      "Epoch 212/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0129 - acc: 0.9969 - val_loss: 0.4620 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.93252\n",
      "Epoch 213/250\n",
      "7047/7047 [==============================] - 2s 298us/step - loss: 0.0125 - acc: 0.9972 - val_loss: 0.4613 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.93252\n",
      "Epoch 214/250\n",
      "7047/7047 [==============================] - 2s 286us/step - loss: 0.0128 - acc: 0.9973 - val_loss: 0.4619 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.93252\n",
      "Epoch 215/250\n",
      "7047/7047 [==============================] - 2s 296us/step - loss: 0.0136 - acc: 0.9965 - val_loss: 0.4610 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.93252\n",
      "Epoch 216/250\n",
      "7047/7047 [==============================] - 2s 286us/step - loss: 0.0125 - acc: 0.9969 - val_loss: 0.4602 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.93252\n",
      "Epoch 217/250\n",
      "7047/7047 [==============================] - 2s 286us/step - loss: 0.0128 - acc: 0.9969 - val_loss: 0.4598 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.93252\n",
      "Epoch 218/250\n",
      "7047/7047 [==============================] - 2s 291us/step - loss: 0.0122 - acc: 0.9973 - val_loss: 0.4621 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.93252\n",
      "Epoch 219/250\n",
      "7047/7047 [==============================] - 2s 285us/step - loss: 0.0119 - acc: 0.9977 - val_loss: 0.4609 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.93252\n",
      "Epoch 220/250\n",
      "7047/7047 [==============================] - 2s 291us/step - loss: 0.0120 - acc: 0.9977 - val_loss: 0.4608 - val_acc: 0.9282\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.93252\n",
      "Epoch 221/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0138 - acc: 0.9967 - val_loss: 0.4631 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.93252\n",
      "Epoch 222/250\n",
      "7047/7047 [==============================] - 2s 297us/step - loss: 0.0126 - acc: 0.9970 - val_loss: 0.4634 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.93252\n",
      "Epoch 223/250\n",
      "7047/7047 [==============================] - 2s 305us/step - loss: 0.0129 - acc: 0.9969 - val_loss: 0.4654 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.93252\n",
      "Epoch 224/250\n",
      "7047/7047 [==============================] - 2s 306us/step - loss: 0.0132 - acc: 0.9962 - val_loss: 0.4650 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.93252\n",
      "Epoch 225/250\n",
      "7047/7047 [==============================] - 2s 304us/step - loss: 0.0131 - acc: 0.9974 - val_loss: 0.4625 - val_acc: 0.9275\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.93252\n",
      "Epoch 226/250\n",
      "7047/7047 [==============================] - 2s 295us/step - loss: 0.0111 - acc: 0.9983 - val_loss: 0.4614 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.93252\n",
      "Epoch 227/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0117 - acc: 0.9977 - val_loss: 0.4610 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.93252\n",
      "Epoch 228/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0126 - acc: 0.9976 - val_loss: 0.4626 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.93252\n",
      "Epoch 229/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0132 - acc: 0.9965 - val_loss: 0.4623 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.93252\n",
      "Epoch 230/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0131 - acc: 0.9972 - val_loss: 0.4647 - val_acc: 0.9268\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.93252\n",
      "Epoch 231/250\n",
      "7047/7047 [==============================] - 2s 293us/step - loss: 0.0136 - acc: 0.9969 - val_loss: 0.4629 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.93252\n",
      "Epoch 232/250\n",
      "7047/7047 [==============================] - 2s 291us/step - loss: 0.0134 - acc: 0.9967 - val_loss: 0.4649 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.93252\n",
      "Epoch 233/250\n",
      "7047/7047 [==============================] - 2s 293us/step - loss: 0.0129 - acc: 0.9967 - val_loss: 0.4652 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.93252\n",
      "Epoch 234/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.4644 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.93252\n",
      "Epoch 235/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0107 - acc: 0.9977 - val_loss: 0.4642 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.93252\n",
      "Epoch 236/250\n",
      "7047/7047 [==============================] - 2s 293us/step - loss: 0.0127 - acc: 0.9966 - val_loss: 0.4646 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.93252\n",
      "Epoch 237/250\n",
      "7047/7047 [==============================] - 2s 293us/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.4650 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.93252\n",
      "Epoch 238/250\n",
      "7047/7047 [==============================] - 2s 293us/step - loss: 0.0150 - acc: 0.9963 - val_loss: 0.4664 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.93252\n",
      "Epoch 239/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0111 - acc: 0.9976 - val_loss: 0.4670 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.93252\n",
      "Epoch 240/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0120 - acc: 0.9977 - val_loss: 0.4660 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.93252\n",
      "Epoch 241/250\n",
      "7047/7047 [==============================] - 2s 293us/step - loss: 0.0141 - acc: 0.9960 - val_loss: 0.4653 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.93252\n",
      "Epoch 242/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0120 - acc: 0.9965 - val_loss: 0.4656 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.93252\n",
      "Epoch 243/250\n",
      "7047/7047 [==============================] - 2s 293us/step - loss: 0.0118 - acc: 0.9979 - val_loss: 0.4648 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.93252\n",
      "Epoch 244/250\n",
      "7047/7047 [==============================] - 2s 293us/step - loss: 0.0118 - acc: 0.9976 - val_loss: 0.4651 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.93252\n",
      "Epoch 245/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0124 - acc: 0.9973 - val_loss: 0.4649 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.93252\n",
      "Epoch 246/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0115 - acc: 0.9979 - val_loss: 0.4656 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.93252\n",
      "Epoch 247/250\n",
      "7047/7047 [==============================] - 2s 293us/step - loss: 0.0116 - acc: 0.9967 - val_loss: 0.4666 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.93252\n",
      "Epoch 248/250\n",
      "7047/7047 [==============================] - 2s 293us/step - loss: 0.0119 - acc: 0.9979 - val_loss: 0.4669 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.93252\n",
      "Epoch 249/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0141 - acc: 0.9970 - val_loss: 0.4670 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.93252\n",
      "Epoch 250/250\n",
      "7047/7047 [==============================] - 2s 292us/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.4672 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.93252\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(loss='categorical_crossentropy',\n",
    "                optimizer=keras.optimizers.Adam(lr=0.001,epsilon=1e-04),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "results = model_2.fit(X_train,Y_train,epochs=250,batch_size=128,validation_data=(X_test,Y_test),callbacks=[cb_checkpoint,lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_weights_2 = [layer.get_weights() for layer in model_2.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(28, 28, 1))\n",
    "\n",
    "#x_1 = conv1_layer_2(input_1)\n",
    "#x_1 = conv2_layer_2(x_1)\n",
    "\n",
    "x_1 = Conv2D(32, kernel_size=3, padding=\"valid\", activation = 'relu')(input_1)\n",
    "x_1 = BatchNormalization()(x_1)\n",
    "x_1 = ReLU()(x_1)\n",
    "x_1 = Dropout(0.45)(x_1)\n",
    "\n",
    "x_1 = Conv2D(64, kernel_size=3, padding=\"valid\", activation = 'relu')(x_1)\n",
    "x_1 = BatchNormalization()(x_1)\n",
    "x_1 = ReLU()(x_1)\n",
    "x_1 = Dropout(0.45)(x_1)\n",
    "\n",
    "x_1 = Conv2D(128, kernel_size=3, padding=\"valid\", activation = 'relu')(x_1)\n",
    "x_1 = BatchNormalization()(x_1)\n",
    "x_1 = ReLU()(x_1)\n",
    "x_1 = Dropout(0.45)(x_1)\n",
    "\n",
    "x_1 = Conv2D(256, kernel_size=3, padding=\"valid\", activation = 'relu')(x_1)\n",
    "x_1 = BatchNormalization()(x_1)\n",
    "x_1 = ReLU()(x_1)\n",
    "x_1 = Dropout(0.45)(x_1)\n",
    "\n",
    "x_1 = GlobalAveragePooling2D()(x_1)\n",
    "x_1 = Dropout(0.45)(x_1)\n",
    "\n",
    "\n",
    "# lstm part\n",
    "input_2 = Input(shape=(64, 2))\n",
    "\n",
    "x_2 = Conv1D(32,kernel_size=4, padding='same',strides=1)(input_2)\n",
    "x_2 = BatchNormalization(momentum=0.8)(x_2)\n",
    "x_2 = LeakyReLU(0.2)(x_2)\n",
    "x_2 = Dropout(0.5)(x_2)\n",
    "\n",
    "x_2 = Conv1D(64,kernel_size=5, strides=1, padding='same')(x_2)\n",
    "x_2 = BatchNormalization(momentum=0.8)(x_2)\n",
    "x_2 = LeakyReLU(alpha=0.2)(x_2)\n",
    "x_2 = Dropout(0.5)(x_2)\n",
    "\n",
    "x_2 = Conv1D(128, kernel_size=6, strides=1, padding='same')(x_2)\n",
    "x_2 = BatchNormalization(momentum=0.8)(x_2)\n",
    "x_2 = LeakyReLU(0.2)(x_2)\n",
    "x_2 = Dropout(0.5)(x_2)\n",
    "\n",
    "\n",
    "x_2 = Conv1D(256, kernel_size=7, strides=1, padding='same')(x_2)\n",
    "x_2 = BatchNormalization(momentum=0.8)(x_2)\n",
    "x_2 = LeakyReLU(0.2)(x_2)\n",
    "x_2 = Dropout(0.5)(x_2)\n",
    "\n",
    "x_2 = Conv1D(512, kernel_size=8, strides=1, padding='same')(x_2)\n",
    "x_2 = BatchNormalization(momentum=0.8)(x_2)\n",
    "x_2 = LeakyReLU(0.2)(x_2)\n",
    "x_2 = Dropout(0.5)(x_2)\n",
    "\n",
    "x_2 = GlobalAveragePooling1D()(x_2)\n",
    "\n",
    "\n",
    "\n",
    "merged = concatenate([x_1,x_2])\n",
    "\n",
    "m = Dense(class_num, activation='softmax')(merged)\n",
    "\n",
    "model_3 = Model(inputs=[input_1, input_2], outputs = m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 64, 2)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 64, 32)       288         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 64, 32)       128         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 32)       0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 26, 26, 32)   320         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 64, 32)       0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 26, 26, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 64, 64)       10304       dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 26, 26, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 64, 64)       256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 26, 26, 32)   0           re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 64, 64)       0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 24, 24, 64)   18496       dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 64, 64)       0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 24, 24, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 64, 128)      49280       dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 24, 24, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 64, 128)      512         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 24, 24, 64)   0           re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 64, 128)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 22, 22, 128)  73856       dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 64, 128)      0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 22, 22, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 64, 256)      229632      dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 22, 22, 128)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 256)      1024        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 22, 22, 128)  0           re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 64, 256)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 20, 20, 256)  295168      dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 64, 256)      0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 20, 20, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 64, 512)      1049088     dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 20, 20, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 512)      2048        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 20, 20, 256)  0           re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 64, 512)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 256)          0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 64, 512)      0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 256)          0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 512)          0           dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 768)          0           dropout_30[0][0]                 \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 26)           19994       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,752,314\n",
      "Trainable params: 1,749,370\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "temp_weights_3 = [layer.get_weights() for layer in model_3.layers]\n",
    "print(len(temp_weights_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n",
      "1 6\n",
      "2 8\n",
      "3 10\n",
      "4 12\n",
      "5 14\n",
      "6 16\n",
      "7 18\n",
      "8 20\n",
      "9 22\n",
      "10 24\n",
      "11 26\n",
      "12 28\n",
      "13 30\n",
      "14 32\n",
      "15 34\n",
      "16 36\n",
      "17 38\n",
      "18 40\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    model_3.layers[i].set_weights(temp_weights[i])\n",
    "for i, j in enumerate(range(4, 41, 2)):\n",
    "    print(i,j)\n",
    "    model_3.layers[j].set_weights(temp_weights[i+3])\n",
    "for i, j in enumerate(range(3,41,2)):\n",
    "    model_3.layers[j].set_weights(temp_weights_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kist-student/anaconda3/envs/tensor/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/kist-student/anaconda3/envs/tensor/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# minmax 실행\n",
    "train_x = dp_train.point[:,:,0].reshape((-1,1))\n",
    "test_x = dp_test.point[:,:,0].reshape((-1,1))\n",
    "\n",
    "train_y = dp_train.point[:,:,1].reshape((-1,1))\n",
    "test_y = dp_test.point[:,:,1].reshape((-1,1))\n",
    "\n",
    "data_x = scaler.fit_transform(train_x).reshape((-1,64,1))\n",
    "data_test_x = scaler.transform(test_x).reshape((-1,64,1))\n",
    "\n",
    "data_y = scaler_.fit_transform(train_y).reshape((-1,64,1))\n",
    "data_test_y = scaler_.transform(test_y).reshape((-1,64,1))\n",
    "\n",
    "data = np.hstack((data_x,data_y)).reshape((-1,64,2),order='F')\n",
    "data_test = np.hstack((data_test_x,data_test_y)).reshape((-1,64,2),order='F')\n",
    "\n",
    "#train set test set 나누기\n",
    "X_train = data[:,:,:]\n",
    "#X_train_ = copy.deepcopy(dp.point)\n",
    "X_test = data_test[:,:,:]\n",
    "X_test_ = copy.deepcopy(data[:,:,:])\n",
    "\n",
    "X_train_img = dp_train.images[:]\n",
    "X_test_img = dp_test.images[:]\n",
    "Y_train = dp_train.label[:]\n",
    "Y_test = dp_test.label[:]\n",
    "\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train,num_classes=class_num, dtype='float32')\n",
    "Y_test = keras.utils.to_categorical(Y_test,num_classes=class_num, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7047 samples, validate on 1393 samples\n",
      "Epoch 1/250\n",
      "7047/7047 [==============================] - 6s 856us/step - loss: 0.8708 - acc: 0.8104 - val_loss: 0.2622 - val_acc: 0.9440\n",
      "Epoch 2/250\n",
      "7047/7047 [==============================] - 3s 454us/step - loss: 0.1210 - acc: 0.9844 - val_loss: 0.2470 - val_acc: 0.9311\n",
      "Epoch 3/250\n",
      "7047/7047 [==============================] - 3s 453us/step - loss: 0.0696 - acc: 0.9913 - val_loss: 0.2076 - val_acc: 0.9368\n",
      "Epoch 4/250\n",
      "7047/7047 [==============================] - 3s 454us/step - loss: 0.0504 - acc: 0.9936 - val_loss: 0.1967 - val_acc: 0.9375\n",
      "Epoch 5/250\n",
      "7047/7047 [==============================] - 3s 453us/step - loss: 0.0384 - acc: 0.9957 - val_loss: 0.2296 - val_acc: 0.9304\n",
      "Epoch 6/250\n",
      "7047/7047 [==============================] - 3s 452us/step - loss: 0.0312 - acc: 0.9962 - val_loss: 0.2225 - val_acc: 0.9311\n",
      "Epoch 7/250\n",
      "7047/7047 [==============================] - 3s 453us/step - loss: 0.0393 - acc: 0.9936 - val_loss: 0.2078 - val_acc: 0.9347\n",
      "Epoch 8/250\n",
      "7047/7047 [==============================] - 3s 454us/step - loss: 0.0278 - acc: 0.9969 - val_loss: 0.2356 - val_acc: 0.9318\n",
      "Epoch 9/250\n",
      "7047/7047 [==============================] - 3s 455us/step - loss: 0.0251 - acc: 0.9960 - val_loss: 0.2092 - val_acc: 0.9289\n",
      "Epoch 10/250\n",
      "7047/7047 [==============================] - 3s 454us/step - loss: 0.0347 - acc: 0.9932 - val_loss: 0.2063 - val_acc: 0.9368\n",
      "Epoch 11/250\n",
      "7047/7047 [==============================] - 3s 454us/step - loss: 0.0201 - acc: 0.9969 - val_loss: 0.1860 - val_acc: 0.9375\n",
      "Epoch 12/250\n",
      "7047/7047 [==============================] - 3s 454us/step - loss: 0.0160 - acc: 0.9980 - val_loss: 0.2037 - val_acc: 0.9340\n",
      "Epoch 13/250\n",
      "7047/7047 [==============================] - 3s 458us/step - loss: 0.0171 - acc: 0.9973 - val_loss: 0.2253 - val_acc: 0.9304\n",
      "Epoch 14/250\n",
      "7047/7047 [==============================] - 3s 455us/step - loss: 0.0137 - acc: 0.9983 - val_loss: 0.2350 - val_acc: 0.9318\n",
      "Epoch 15/250\n",
      "7047/7047 [==============================] - 3s 455us/step - loss: 0.0142 - acc: 0.9966 - val_loss: 0.2236 - val_acc: 0.9340\n",
      "Epoch 16/250\n",
      "7047/7047 [==============================] - 3s 456us/step - loss: 0.0143 - acc: 0.9976 - val_loss: 0.1900 - val_acc: 0.9404\n",
      "Epoch 17/250\n",
      "7047/7047 [==============================] - 3s 458us/step - loss: 0.0125 - acc: 0.9973 - val_loss: 0.1853 - val_acc: 0.9411\n",
      "Epoch 18/250\n",
      "7047/7047 [==============================] - 3s 457us/step - loss: 0.0111 - acc: 0.9984 - val_loss: 0.2185 - val_acc: 0.9311\n",
      "Epoch 19/250\n",
      "7047/7047 [==============================] - 3s 455us/step - loss: 0.0098 - acc: 0.9987 - val_loss: 0.2233 - val_acc: 0.9375\n",
      "Epoch 20/250\n",
      "7047/7047 [==============================] - 3s 456us/step - loss: 0.0093 - acc: 0.9989 - val_loss: 0.1857 - val_acc: 0.9419\n",
      "Epoch 21/250\n",
      "7047/7047 [==============================] - 3s 456us/step - loss: 0.0109 - acc: 0.9972 - val_loss: 0.2342 - val_acc: 0.9347\n",
      "Epoch 22/250\n",
      "7047/7047 [==============================] - 3s 456us/step - loss: 0.0084 - acc: 0.9990 - val_loss: 0.1934 - val_acc: 0.9462\n",
      "Epoch 23/250\n",
      "7047/7047 [==============================] - 3s 455us/step - loss: 0.0075 - acc: 0.9993 - val_loss: 0.2120 - val_acc: 0.9404\n",
      "Epoch 24/250\n",
      "7047/7047 [==============================] - 3s 457us/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.1872 - val_acc: 0.9433\n",
      "Epoch 25/250\n",
      "7047/7047 [==============================] - 3s 460us/step - loss: 0.0063 - acc: 0.9996 - val_loss: 0.2073 - val_acc: 0.9361\n",
      "Epoch 26/250\n",
      "7047/7047 [==============================] - 3s 457us/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.1996 - val_acc: 0.9404\n",
      "Epoch 27/250\n",
      "7047/7047 [==============================] - 3s 461us/step - loss: 0.0078 - acc: 0.9989 - val_loss: 0.2125 - val_acc: 0.9397\n",
      "Epoch 28/250\n",
      "7047/7047 [==============================] - 3s 461us/step - loss: 0.0069 - acc: 0.9993 - val_loss: 0.2034 - val_acc: 0.9447\n",
      "Epoch 29/250\n",
      "4480/7047 [==================>...........] - ETA: 1s - loss: 0.0064 - acc: 0.9989"
     ]
    }
   ],
   "source": [
    "model_3.compile(loss='categorical_crossentropy',\n",
    "                optimizer=keras.optimizers.Adam(lr=0.001,epsilon=1e-04),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "hist_2 = model_3.fit([X_train_img,X_train],Y_train,epochs=250,batch_size=128,validation_data=([X_test_img,X_test],Y_test),callbacks=[lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_3.evaluate([X_test_img,X_test], Y_test, verbose=0)\n",
    "pred = model_3.predict([X_test_img,X_test])\n",
    "true_value = np.argmax(Y_test,1)\n",
    "predict_value = np.argmax(pred,1)\n",
    "print(np.argmax(pred,axis=1))\n",
    "print(score[1]*100)\n",
    "#print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*score))\n",
    "list_ = []\n",
    "for i in range(np.size(true_value,0)):\n",
    "  if(true_value[i] != predict_value[i]):\n",
    "    if(number):\n",
    "      print('t:{},p:{}'.format(true_value[i],predict_value[i]))\n",
    "    else:\n",
    "      print('t:{},p:{}'.format(chr(97+true_value[i]),chr(97+predict_value[i])))\n",
    "    list_.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
